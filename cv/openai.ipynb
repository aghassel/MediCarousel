{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def get_marker_color(image_path):\n",
    "    def encode_image(img_path):\n",
    "        with open(img_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"In one word, tell me what is the color of the Crayola marker in this image?\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"low\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    # Extract color information from the response\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        color_info = response_json.get('choices', [])[0].get('message', {}).get('content', '')\n",
    "        return color_info\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue\n"
     ]
    }
   ],
   "source": [
    "image_path = \"blue.jpg\"\n",
    "print(get_marker_color(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scalpel.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"scalpel.m4a\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file, \n",
    "  response_format=\"text\"\n",
    ")\n",
    "\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sF2H4WDk8FhLDAuc3nHrVpFY83RlAvJtb1lR5jFTBMK9yuRIq/65fw==\n"
     ]
    }
   ],
   "source": [
    "access_key = os.environ.get('PORCUPINE_API_KEY')\n",
    "\n",
    "print(access_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for the wake word...\n",
      "Wake word detected!\n",
      "Recording for 2 seconds...\n",
      "Recording finished.\n",
      "Thank you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pvporcupine\n",
    "import pyaudio\n",
    "import struct\n",
    "import wave\n",
    "import openai\n",
    "\n",
    "access_key = os.environ.get('PORCUPINE_API_KEY')\n",
    "custom_keyword_path = 'hey-med-carousel_en_windows_v3_0_0.ppn'\n",
    "\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=access_key,\n",
    "    keyword_paths=[custom_keyword_path]\n",
    ")\n",
    "\n",
    "def record_audio(duration=2, filename=\"output.wav\"):\n",
    "    \"\"\"\n",
    "    Record audio from the default microphone for the given duration\n",
    "    and save it to the specified filename.\n",
    "    \"\"\"\n",
    "    pa = pyaudio.PyAudio()\n",
    "\n",
    "    stream = pa.open(format=pyaudio.paInt16, channels=1, rate=16000,\n",
    "                     input=True, frames_per_buffer=1024)\n",
    "\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(16000 / 1024 * duration)):\n",
    "        data = stream.read(1024)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    pa.terminate()\n",
    "\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)\n",
    "        wf.setsampwidth(pa.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(16000)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "def transcribe_audio(filename):\n",
    "    \"\"\"\n",
    "    Transcribe the specified audio file using OpenAI's Whisper.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    with open(filename, \"rb\") as audio_file:\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for the wake word...\n",
      "Wake word detected!\n",
      "Recording for 2 seconds...\n",
      "Recording finished.\n",
      "Forceps.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa = pyaudio.PyAudio()\n",
    "audio_stream = pa.open(rate=porcupine.sample_rate, channels=1,\n",
    "                       format=pyaudio.paInt16, input=True,\n",
    "                       frames_per_buffer=porcupine.frame_length)\n",
    "\n",
    "print(\"Listening for the wake word...\")\n",
    "\n",
    "while True:\n",
    "    pcm = audio_stream.read(porcupine.frame_length)\n",
    "    pcm = struct.unpack_from(\"h\" * porcupine.frame_length, pcm)\n",
    "\n",
    "    if porcupine.process(pcm) >= 0:\n",
    "        print(\"Wake word detected!\")\n",
    "        break\n",
    "\n",
    "audio_stream.close()\n",
    "pa.terminate()\n",
    "\n",
    "# Record and transcribe audio\n",
    "record_audio(duration=2, filename=\"output.wav\")\n",
    "transcription = transcribe_audio(\"output.wav\")\n",
    "print(transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ELEC475",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
